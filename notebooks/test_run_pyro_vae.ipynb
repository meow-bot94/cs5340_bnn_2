{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-16 23:39:45] 20183 root {logger_initializer-47} INFO - Current process ID: 20183\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ssl\n",
    "import matplotlib.pyplot as plt\n",
    "from src.logger.logger_initializer import LoggerInitializer\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "device = 'cuda'\n",
    "torch.__version__\n",
    "\n",
    "LoggerInitializer().init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from src.data_loader.dataset_getter import DatasetGetter\n",
    "dataset = DatasetGetter('../../bayesian_test/data', batch_size=12).get()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    image_dimension = 224*224*3\n",
    "\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, self.image_dimension)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.sigmoid(self.fc21(hidden))\n",
    "        return loc_img\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    image_dimension = 224*224*3\n",
    "\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(self.image_dimension, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward computation on the image x\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        x = x.reshape(-1, self.image_dimension)\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    image_dimension = 224*224*3\n",
    "\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder(z)\n",
    "            # score against actual images\n",
    "            print(f'{loc_img=}')\n",
    "            bdist = dist.Bernoulli(loc_img).to_event(1)\n",
    "            print(f'{bdist=}')\n",
    "            pyro.sample(\"obs\", bdist, obs=x.reshape(-1, self.image_dimension))\n",
    "            # pyro.sample(\"obs\", dist.Normal(loc_img, 0.1).to_event(1), obs=x.reshape(-1, self.image_dimension))\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "vae = VAE()\n",
    "optimizer = ClippedAdam({\"lr\": 1.0e-3})\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "VAE(\n  (encoder): Encoder(\n    (fc1): Linear(in_features=150528, out_features=400, bias=True)\n    (fc21): Linear(in_features=400, out_features=50, bias=True)\n    (fc22): Linear(in_features=400, out_features=50, bias=True)\n    (softplus): Softplus(beta=1, threshold=20)\n  )\n  (decoder): Decoder(\n    (fc1): Linear(in_features=50, out_features=400, bias=True)\n    (fc21): Linear(in_features=400, out_features=150528, bias=True)\n    (softplus): Softplus(beta=1, threshold=20)\n    (sigmoid): Sigmoid()\n  )\n)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc_img=tensor([[0.3643, 0.4692, 0.4283,  ..., 0.3545, 0.6339, 0.5498],\n",
      "        [0.5261, 0.4305, 0.5122,  ..., 0.3083, 0.5748, 0.6241],\n",
      "        [0.5419, 0.4872, 0.4511,  ..., 0.4710, 0.5999, 0.5004],\n",
      "        ...,\n",
      "        [0.4968, 0.4398, 0.5012,  ..., 0.4959, 0.5198, 0.5171],\n",
      "        [0.4801, 0.3356, 0.4134,  ..., 0.4375, 0.6360, 0.5183],\n",
      "        [0.4215, 0.3972, 0.3928,  ..., 0.3917, 0.6307, 0.5447]],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "bdist=Independent(Bernoulli(probs: torch.Size([12, 150528])), 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error while computing log_prob at site 'obs':\nExpected value argument (Tensor of shape (12, 150528)) to be within the support (Boolean()) of the distribution Bernoulli(probs: torch.Size([12, 150528])), but found invalid values:\ntensor([[ 1.9578,  1.9407,  1.9407,  ..., -1.2641, -1.2816, -1.2816],\n        [ 1.8208,  1.8208,  1.8208,  ..., -0.0092,  0.0082,  0.0431],\n        [ 1.4098,  1.3927,  1.3927,  ..., -0.7238, -0.7238, -0.7413],\n        ...,\n        [ 1.0673,  1.0673,  1.0673,  ...,  0.9842,  0.9668,  0.9494],\n        [ 1.5468,  1.5468,  1.5468,  ...,  0.9668,  0.9319,  0.8797],\n        [ 2.0777,  2.0777,  2.0777,  ...,  1.8905,  1.8905,  1.8905]],\n       device='cuda:0')\n        Trace Shapes:                     \n         Param Sites:                     \n decoder$$$fc1.weight    400     50       \n   decoder$$$fc1.bias           400       \ndecoder$$$fc21.weight 150528    400       \n  decoder$$$fc21.bias        150528       \n        Sample Sites:                     \n          latent dist     12      |     50\n                value     12      |     50\n             log_prob     12      |       \n             obs dist     12      | 150528\n                value     12      | 150528",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/poutine/trace_struct.py:230\u001B[0m, in \u001B[0;36mTrace.compute_log_prob\u001B[0;34m(self, site_filter)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 230\u001B[0m     log_p \u001B[38;5;241m=\u001B[39m \u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_prob\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43margs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkwargs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/distributions/independent.py:95\u001B[0m, in \u001B[0;36mIndependent.log_prob\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_prob\u001B[39m(\u001B[38;5;28mself\u001B[39m, value):\n\u001B[0;32m---> 95\u001B[0m     log_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_dist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _sum_rightmost(log_prob, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreinterpreted_batch_ndims)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/distributions/bernoulli.py:100\u001B[0m, in \u001B[0;36mBernoulli.log_prob\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_args:\n\u001B[0;32m--> 100\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m logits, value \u001B[38;5;241m=\u001B[39m broadcast_all(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogits, value)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/distributions/distribution.py:293\u001B[0m, in \u001B[0;36mDistribution._validate_sample\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m valid\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected value argument \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    295\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto be within the support (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(support)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof the distribution \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    298\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    299\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected value argument (Tensor of shape (12, 150528)) to be within the support (Boolean()) of the distribution Bernoulli(probs: torch.Size([12, 150528])), but found invalid values:\ntensor([[ 1.9578,  1.9407,  1.9407,  ..., -1.2641, -1.2816, -1.2816],\n        [ 1.8208,  1.8208,  1.8208,  ..., -0.0092,  0.0082,  0.0431],\n        [ 1.4098,  1.3927,  1.3927,  ..., -0.7238, -0.7238, -0.7413],\n        ...,\n        [ 1.0673,  1.0673,  1.0673,  ...,  0.9842,  0.9668,  0.9494],\n        [ 1.5468,  1.5468,  1.5468,  ...,  0.9668,  0.9319,  0.8797],\n        [ 2.0777,  2.0777,  2.0777,  ...,  1.8905,  1.8905,  1.8905]],\n       device='cuda:0')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m train_elbo \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m----> 3\u001B[0m     total_epoch_loss_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43msvi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cuda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     train_elbo\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;241m-\u001B[39mtotal_epoch_loss_train)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[epoch \u001B[39m\u001B[38;5;132;01m%03d\u001B[39;00m\u001B[38;5;124m]  average training loss: \u001B[39m\u001B[38;5;132;01m%.4f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (epoch, total_epoch_loss_train))\n",
      "Cell \u001B[0;32mIn[39], line 17\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(svi, train_loader, use_cuda)\u001B[0m\n\u001B[1;32m     15\u001B[0m         x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# do ELBO gradient and accumulate loss\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m     epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43msvi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# return epoch loss\u001B[39;00m\n\u001B[1;32m     20\u001B[0m normalizer_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/svi.py:145\u001B[0m, in \u001B[0;36mSVI.step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;66;03m# get loss and compute gradients\u001B[39;00m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m poutine\u001B[38;5;241m.\u001B[39mtrace(param_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m param_capture:\n\u001B[0;32m--> 145\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_and_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mguide\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\n\u001B[1;32m    148\u001B[0m     site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39munconstrained() \u001B[38;5;28;01mfor\u001B[39;00m site \u001B[38;5;129;01min\u001B[39;00m param_capture\u001B[38;5;241m.\u001B[39mtrace\u001B[38;5;241m.\u001B[39mnodes\u001B[38;5;241m.\u001B[39mvalues()\n\u001B[1;32m    149\u001B[0m )\n\u001B[1;32m    151\u001B[0m \u001B[38;5;66;03m# actually perform gradient steps\u001B[39;00m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001B[39;00m\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:140\u001B[0m, in \u001B[0;36mTrace_ELBO.loss_and_grads\u001B[0;34m(self, model, guide, *args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# grab a trace from the generator\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_trace, guide_trace \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_traces(model, guide, args, kwargs):\n\u001B[1;32m    141\u001B[0m     loss_particle, surrogate_loss_particle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_differentiable_loss_particle(\n\u001B[1;32m    142\u001B[0m         model_trace, guide_trace\n\u001B[1;32m    143\u001B[0m     )\n\u001B[1;32m    144\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_particle \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_particles\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/elbo.py:182\u001B[0m, in \u001B[0;36mELBO._get_traces\u001B[0;34m(self, model, guide, args, kwargs)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_particles):\n\u001B[0;32m--> 182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_trace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mguide\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:57\u001B[0m, in \u001B[0;36mTrace_ELBO._get_trace\u001B[0;34m(self, model, guide, args, kwargs)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_trace\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, guide, args, kwargs):\n\u001B[1;32m     53\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m    against it.\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 57\u001B[0m     model_trace, guide_trace \u001B[38;5;241m=\u001B[39m \u001B[43mget_importance_trace\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mflat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_plate_nesting\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mguide\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_validation_enabled():\n\u001B[1;32m     61\u001B[0m         check_if_enumerated(guide_trace)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/enum.py:75\u001B[0m, in \u001B[0;36mget_importance_trace\u001B[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001B[0m\n\u001B[1;32m     72\u001B[0m guide_trace \u001B[38;5;241m=\u001B[39m prune_subsample_sites(guide_trace)\n\u001B[1;32m     73\u001B[0m model_trace \u001B[38;5;241m=\u001B[39m prune_subsample_sites(model_trace)\n\u001B[0;32m---> 75\u001B[0m \u001B[43mmodel_trace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_log_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m guide_trace\u001B[38;5;241m.\u001B[39mcompute_score_parts()\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_validation_enabled():\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/poutine/trace_struct.py:236\u001B[0m, in \u001B[0;36mTrace.compute_log_prob\u001B[0;34m(self, site_filter)\u001B[0m\n\u001B[1;32m    234\u001B[0m     _, exc_value, traceback \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mexc_info()\n\u001B[1;32m    235\u001B[0m     shapes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_shapes(last_site\u001B[38;5;241m=\u001B[39msite[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError while computing log_prob at site \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    238\u001B[0m             name, exc_value, shapes\n\u001B[1;32m    239\u001B[0m         )\n\u001B[1;32m    240\u001B[0m     )\u001B[38;5;241m.\u001B[39mwith_traceback(traceback) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    241\u001B[0m site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munscaled_log_prob\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m log_p\n\u001B[1;32m    242\u001B[0m log_p \u001B[38;5;241m=\u001B[39m scale_and_mask(log_p, site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscale\u001B[39m\u001B[38;5;124m\"\u001B[39m], site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/poutine/trace_struct.py:230\u001B[0m, in \u001B[0;36mTrace.compute_log_prob\u001B[0;34m(self, site_filter)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog_prob\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m site:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 230\u001B[0m         log_p \u001B[38;5;241m=\u001B[39m \u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_prob\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m            \u001B[49m\u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43margs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msite\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkwargs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    234\u001B[0m         _, exc_value, traceback \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mexc_info()\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/distributions/independent.py:95\u001B[0m, in \u001B[0;36mIndependent.log_prob\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_prob\u001B[39m(\u001B[38;5;28mself\u001B[39m, value):\n\u001B[0;32m---> 95\u001B[0m     log_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_dist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _sum_rightmost(log_prob, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreinterpreted_batch_ndims)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/distributions/bernoulli.py:100\u001B[0m, in \u001B[0;36mBernoulli.log_prob\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_prob\u001B[39m(\u001B[38;5;28mself\u001B[39m, value):\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_args:\n\u001B[0;32m--> 100\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m     logits, value \u001B[38;5;241m=\u001B[39m broadcast_all(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogits, value)\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mbinary_cross_entropy_with_logits(logits, value, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/distributions/distribution.py:293\u001B[0m, in \u001B[0;36mDistribution._validate_sample\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m    291\u001B[0m valid \u001B[38;5;241m=\u001B[39m support\u001B[38;5;241m.\u001B[39mcheck(value)\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m valid\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected value argument \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    295\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto be within the support (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(support)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof the distribution \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    298\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    299\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Error while computing log_prob at site 'obs':\nExpected value argument (Tensor of shape (12, 150528)) to be within the support (Boolean()) of the distribution Bernoulli(probs: torch.Size([12, 150528])), but found invalid values:\ntensor([[ 1.9578,  1.9407,  1.9407,  ..., -1.2641, -1.2816, -1.2816],\n        [ 1.8208,  1.8208,  1.8208,  ..., -0.0092,  0.0082,  0.0431],\n        [ 1.4098,  1.3927,  1.3927,  ..., -0.7238, -0.7238, -0.7413],\n        ...,\n        [ 1.0673,  1.0673,  1.0673,  ...,  0.9842,  0.9668,  0.9494],\n        [ 1.5468,  1.5468,  1.5468,  ...,  0.9668,  0.9319,  0.8797],\n        [ 2.0777,  2.0777,  2.0777,  ...,  1.8905,  1.8905,  1.8905]],\n       device='cuda:0')\n        Trace Shapes:                     \n         Param Sites:                     \n decoder$$$fc1.weight    400     50       \n   decoder$$$fc1.bias           400       \ndecoder$$$fc21.weight 150528    400       \n  decoder$$$fc21.bias        150528       \n        Sample Sites:                     \n          latent dist     12      |     50\n                value     12      |     50\n             log_prob     12      |       \n             obs dist     12      | 150528\n                value     12      | 150528"
     ]
    }
   ],
   "source": [
    "train_elbo = []\n",
    "for epoch in range(2):\n",
    "    total_epoch_loss_train = train(svi, dataset.train_dataloader, use_cuda=True)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mtrain_dataloader))\n\u001B[1;32m      2\u001B[0m output \u001B[38;5;241m=\u001B[39m vae\u001B[38;5;241m.\u001B[39mguide(x\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataset.train_dataloader))\n",
    "output = vae.guide(x.to(device))\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mtrain_dataloader))\n\u001B[1;32m      4\u001B[0m predictive \u001B[38;5;241m=\u001B[39m Predictive(vae\u001B[38;5;241m.\u001B[39mmodel, guide\u001B[38;5;241m=\u001B[39mvae\u001B[38;5;241m.\u001B[39mguide, num_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m      5\u001B[0m                         return_sites\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobs\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_RETURN\u001B[39m\u001B[38;5;124m\"\u001B[39m))  \u001B[38;5;66;03m# \"linear.weight\"\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m samples \u001B[38;5;241m=\u001B[39m \u001B[43mpredictive\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m predicted_classes \u001B[38;5;241m=\u001B[39m samples[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_RETURN\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(predicted_classes)\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/predictive.py:273\u001B[0m, in \u001B[0;36mPredictive.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    263\u001B[0m     return_sites \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_sites \u001B[38;5;28;01melse\u001B[39;00m return_sites\n\u001B[1;32m    264\u001B[0m     posterior_samples \u001B[38;5;241m=\u001B[39m _predictive(\n\u001B[1;32m    265\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mguide,\n\u001B[1;32m    266\u001B[0m         posterior_samples,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    271\u001B[0m         model_kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m    272\u001B[0m     )\n\u001B[0;32m--> 273\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_predictive\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposterior_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_sites\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_sites\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/predictive.py:127\u001B[0m, in \u001B[0;36m_predictive\u001B[0;34m(model, posterior_samples, num_samples, return_sites, return_trace, parallel, model_args, model_kwargs)\u001B[0m\n\u001B[1;32m    124\u001B[0m     return_site_shapes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_RETURN\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m shape\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m parallel:\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_predictive_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposterior_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_site_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_trace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m trace \u001B[38;5;241m=\u001B[39m poutine\u001B[38;5;241m.\u001B[39mtrace(\n\u001B[1;32m    138\u001B[0m     poutine\u001B[38;5;241m.\u001B[39mcondition(vectorize(model), reshaped_samples)\n\u001B[1;32m    139\u001B[0m )\u001B[38;5;241m.\u001B[39mget_trace(\u001B[38;5;241m*\u001B[39mmodel_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m    140\u001B[0m predictions \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/predictive.py:61\u001B[0m, in \u001B[0;36m_predictive_sequential\u001B[0;34m(model, posterior_samples, model_args, model_kwargs, num_samples, return_site_shapes, return_trace)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m collected\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m     62\u001B[0m         site: torch\u001B[38;5;241m.\u001B[39mstack([s[site] \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m collected])\u001B[38;5;241m.\u001B[39mreshape(shape)\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m site, shape \u001B[38;5;129;01min\u001B[39;00m return_site_shapes\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m     64\u001B[0m     }\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/infer/predictive.py:62\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m collected\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m---> 62\u001B[0m         site: \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m[\u001B[49m\u001B[43msite\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcollected\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(shape)\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m site, shape \u001B[38;5;129;01min\u001B[39;00m return_site_shapes\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m     64\u001B[0m     }\n",
      "\u001B[0;31mTypeError\u001B[0m: expected Tensor as element 0 in argument 0, but got NoneType"
     ]
    }
   ],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "x, y = next(iter(dataset.train_dataloader))\n",
    "predictive = Predictive(vae.model, guide=vae.guide, num_samples=10,\n",
    "                        return_sites=(\"obs\", \"_RETURN\"))  # \"linear.weight\"\n",
    "samples = predictive(x.to(device))\n",
    "predicted_classes = samples['_RETURN'].cpu().numpy()\n",
    "print(predicted_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "state_dict = pyro.get_param_store()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'latent'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mstate_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlatent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m/anaconda_env/projects/wlbbc/bayesian_test/lib/python3.9/site-packages/pyro/params/param_store.py:106\u001B[0m, in \u001B[0;36mParamStoreDict.__getitem__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m    103\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m    Get the *constrained* value of a named parameter.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     unconstrained_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_params\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;66;03m# compute the constrained value\u001B[39;00m\n\u001B[1;32m    109\u001B[0m     constraint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constraints[name]\n",
      "\u001B[0;31mKeyError\u001B[0m: 'latent'"
     ]
    }
   ],
   "source": [
    "state_dict['latent']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "bayesian_test",
   "language": "python",
   "display_name": "Python 3 (bayesian test)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
